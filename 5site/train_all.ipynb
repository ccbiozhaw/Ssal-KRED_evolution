{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "/home/david/anaconda3/envs/kredPaper/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set()\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern,WhiteKernel,RBF,ConstantKernel as C\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import OrderedDict\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import norm\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aaindex_dict.pickle', 'rb') as handle:\n",
    "    aa_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class do_ml(object):\n",
    "    \n",
    "    def __init__(self,df,features_AS,target,encoding,components = 11,verbose = True,model_type = \"gp\",testing = True):\n",
    "        \n",
    "        self.seed_everything()\n",
    "    \n",
    "        self.df = df        \n",
    "        self.features_AS = features_AS\n",
    "        self.target = target\n",
    "        \n",
    "        self.encoding = encoding\n",
    "        self.components = components\n",
    "        \n",
    "        self.prepare_encoding(self.components)\n",
    "        \n",
    "        self.encoded_as_df = self.make_t_scale_df(self.df[self.features_AS])\n",
    "        self.y = self.df[self.target]\n",
    "        \n",
    "        self.all_as = [\"R\",\"H\",\"K\",\"D\",\"E\",\"S\",\"T\",\"N\",\"Q\",\"C\",\"G\",\"P\",\"A\",\"V\",\"I\",\"L\",\"M\",\"F\",\"W\",\"Y\"]\n",
    "        self.len_cats = len(features_AS)\n",
    "        \n",
    "        all_as_combs = list(itertools.product(self.all_as,repeat = self.len_cats))\n",
    "        \n",
    "        self.all_as_df = pd.DataFrame(all_as_combs,columns = self.features_AS)\n",
    "        self.all_as_df_encoded = self.make_t_scale_df(self.all_as_df[self.features_AS])\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        self.testing = testing\n",
    "        \n",
    "    def prepare_encoding(self,components):\n",
    "        \n",
    "        pc = PCA(n_components = components)\n",
    "        pc = pc.fit_transform(np.stack(self.encoding.values()))\n",
    "        \n",
    "        encoding_df = pd.DataFrame({\"AS\":list(self.encoding.keys())})\n",
    "        \n",
    "        for i in range(pc.shape[1]):\n",
    "            encoding_df[\"f_\"+str(i)] = pc[:,i]\n",
    "                \n",
    "        for t in encoding_df.columns[1:]:\n",
    "            sclr = StandardScaler()\n",
    "            encoding_df[t] = sclr.fit_transform(np.array(encoding_df[t]).reshape((-1,1)))    \n",
    "    \n",
    "        self.encoding_df = encoding_df\n",
    "    \n",
    "    \n",
    "    def make_t_scale_df(self,df):\n",
    "        \n",
    "        cols = df.columns\n",
    "        for t,i in enumerate(cols):\n",
    "            df = pd.merge(df,self.encoding_df, how = \"left\",left_on= i , right_on= \"AS\")\n",
    "            df.drop(\"AS\",axis = 1, inplace = True)\n",
    "            keep_cols =  self.encoding_df.columns[1:]\n",
    "            df.rename(columns = {x: str(x) + \"_\" + str(t + 1) for x in keep_cols},inplace = True)\n",
    "        df.drop(cols,axis = 1, inplace = True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def update_dfs(self,components):\n",
    "        self.prepare_encoding(components)\n",
    "        \n",
    "        self.encoded_as_df = self.make_t_scale_df(self.df[self.features_AS])\n",
    "        self.all_as_df_encoded = self.make_t_scale_df(self.all_as_df[self.features_AS])\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self,n_splits = 10):\n",
    "        \n",
    "        self.target = np.log1p(self.y)\n",
    "\n",
    "        n_splits = 10\n",
    "\n",
    "        cv = KFold(n_splits = n_splits)\n",
    "        \n",
    "        self.oof_pred = np.zeros(len(self.encoded_as_df))\n",
    "        self.oof_all_as_pred = np.zeros(len(self.all_as_df_encoded))\n",
    "\n",
    "        for t,(train_idx,val_idx) in enumerate(cv.split(self.encoded_as_df)):            \n",
    "            x_train,y_train = self.encoded_as_df.iloc[train_idx], self.target[train_idx]\n",
    "            x_val,y_val = self.encoded_as_df.iloc[val_idx], self.target[val_idx]\n",
    "\n",
    "            #kernel =  RBF(length_scale_bounds = \"fixed\")\n",
    "            \n",
    "            if self.model_type == \"gp\":\n",
    "                kernel = Matern(length_scale = 1.,nu=1.5)\n",
    "                lreg = GaussianProcessRegressor(kernel)\n",
    "                \n",
    "            elif self.model_type == \"rf\":\n",
    "                lreg = RandomForestRegressor()\n",
    "                \n",
    "            lreg.fit(x_train,y_train)\n",
    "            yhat = lreg.predict(x_val)\n",
    "            \n",
    "            \n",
    "            if not self.testing:\n",
    "                if len(self.all_as_df_encoded) <= 20**3:\n",
    "                    yhat_pred = lreg.predict(self.all_as_df_encoded).astype(\"float16\") #np.ones(len(self.all_as_df_encoded))\n",
    "\n",
    "                else:\n",
    "                    yhat_pred = []\n",
    "                    for sub_df in np.array_split(self.all_as_df_encoded, 25):\n",
    "                        #print(sub_df.shape)\n",
    "                        yhat_pred_sub = lreg.predict(sub_df).astype(\"float16\")\n",
    "                        yhat_pred = np.concatenate([yhat_pred,yhat_pred_sub])\n",
    "                                    \n",
    "            else:\n",
    "                yhat_pred = np.ones(len(self.all_as_df_encoded))\n",
    "                \n",
    "            yhat = np.expm1(yhat.clip(0,10))\n",
    "            yhat_pred = np.expm1(yhat_pred.clip(0,10))\n",
    "            \n",
    "            self.oof_pred[val_idx] = yhat\n",
    "            self.oof_all_as_pred += yhat_pred / n_splits\n",
    "            \n",
    "            r2 = r2_score(np.expm1(y_val),yhat)\n",
    "            mse = mean_squared_error(np.expm1(y_val),yhat)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"{r2}\")\n",
    "             \n",
    "        print(f\"final r2: {r2_score(np.expm1(self.target),self.oof_pred)}\")\n",
    "        print(f\"final mse: {mean_squared_error(np.expm1(self.target),self.oof_pred)}\")\n",
    "        self.final_r2 = r2_score(np.expm1(self.target),self.oof_pred)\n",
    "    \n",
    "    def plot(self):\n",
    "        \n",
    "        lreg = LinearRegression()\n",
    "\n",
    "        lreg.fit(self.oof_pred.reshape(-1, 1),self.y.values.reshape(-1, 1))\n",
    "\n",
    "        x = np.linspace(0,self.oof_pred.max() + self.oof_pred.max()*0.1,300).reshape(-1, 1)\n",
    "        y = lreg.predict(x)\n",
    "\n",
    "        plt.figure(figsize = (15,10))\n",
    "        plt.scatter(self.oof_pred,self.y)\n",
    "        plt.xlabel(\"predicted values\",fontsize = 15)\n",
    "        plt.ylabel(\"measured values\",fontsize = 15)\n",
    "        plt.plot(x,y,c = \"r\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def seed_everything(seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"all_5_train.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_mutations = {}\n",
    "for u in data.library1.unique():\n",
    "    libs = []\n",
    "    for c in [97,174,238,241,242,245]:\n",
    "        am = len(data.loc[data.library1 == u,c].value_counts())\n",
    "        \n",
    "        if am > 4:\n",
    "            libs.append(c)\n",
    "    \n",
    "    libraries_mutations[u] = libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: [174, 238, 241, 242, 245],\n",
       " 4: [174, 238, 241],\n",
       " 3: [238, 241, 242],\n",
       " 2: [241, 242, 245],\n",
       " 1: [174, 242, 245],\n",
       " 6: [97, 174, 238, 241, 242, 245]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libraries_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2453\n",
      "0.5177105177490822\n",
      "0.5444651276402\n",
      "0.5731127269647309\n",
      "0.7826878388432609\n",
      "0.8044627786278676\n",
      "0.8126885925184049\n",
      "0.6837524577824838\n",
      "0.7117470601791686\n",
      "0.5307751337828984\n",
      "0.8391879096053999\n",
      "final r2: 0.7696547121080568\n",
      "final mse: 0.07484251149667637\n",
      "******************** 0.5414771472857345\n"
     ]
    }
   ],
   "source": [
    "feature_cols = libraries_mutations[5]\n",
    "target_cols = \"FO_WT\"\n",
    "    \n",
    "test_lin = data.loc[data.library.isin([1,2,4,5])].reset_index(drop = True)\n",
    "test_lin[\"FO_WT\"] = test_lin.groupby(\"variant\")[\"FO_WT\"].transform(\"mean\")\n",
    "\n",
    "test_lin = test_lin.drop_duplicates(subset = \"variant\").reset_index(drop = True)\n",
    "len_before = len(test_lin)\n",
    "    \n",
    "as_test = [\"R\",\"H\",\"K\",\"D\",\"E\",\"S\",\"T\",\"N\",\"Q\",\"C\",\"G\",\"P\",\"A\",\"V\",\"I\",\"L\",\"M\",\"F\",\"W\",\"Y\"]\n",
    "test_lin = test_lin[test_lin[feature_cols].apply(lambda x: all(x.isin(as_test)),axis = 1)].reset_index(drop = True)\n",
    "len_after = len(test_lin)\n",
    "\n",
    "print(len_after)\n",
    "\n",
    "test_lin[target_cols] = test_lin[target_cols].apply(lambda x: max(0,x))\n",
    "    \n",
    "t = do_ml(test_lin,feature_cols,target_cols,aa_index,verbose = True,components = 13,model_type = \"gp\",testing = False)\n",
    "t.predict()\n",
    "\n",
    "df5_only = list(t.df[t.df[\"library\"] == 5].index)\n",
    "df5_r2 = r2_score(np.expm1(t.target[df5_only]),t.oof_pred[df5_only])\n",
    "\n",
    "print(\"*\" * 20, df5_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df = t.all_as_df\n",
    "all5df[\"preds\"] = t.oof_all_as_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df = all5df.sort_values(\"preds\",ascending = False)[:10000].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df[\"variant\"] = all5df[all5df.columns[:-1]].apply(lambda x: \"\".join(x),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df[\"variant\"]= all5df.variant.apply(lambda x: \"W\"+x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df = all5df.loc[~all5df.variant.isin(test_lin.variant)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df.to_excel(\"predictions_all5.xlsx\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh -N -f -L localhost:8891:localhost:8891 david@ccbio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
