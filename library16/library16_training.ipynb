{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aaindex_dict.pickle', 'rb') as handle:\n",
    "    aa_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class do_ml(object):\n",
    "\n",
    "    def __init__(self, df, features_AS, target, encoding, components=11, verbose=True, model_type=\"gp\", testing=True):\n",
    "\n",
    "        self.seed_everything()\n",
    "\n",
    "        self.df = df\n",
    "        self.features_AS = features_AS\n",
    "        self.target = target\n",
    "\n",
    "        self.encoding = encoding\n",
    "        self.components = components\n",
    "\n",
    "        self.prepare_encoding(self.components)\n",
    "\n",
    "        self.encoded_as_df = self.make_t_scale_df(self.df[self.features_AS])\n",
    "        self.y = self.df[self.target]\n",
    "\n",
    "        self.all_as = [\"R\", \"H\", \"K\", \"D\", \"E\", \"S\", \"T\", \"N\", \"Q\",\n",
    "                       \"C\", \"G\", \"P\", \"A\", \"V\", \"I\", \"L\", \"M\", \"F\", \"W\", \"Y\"]\n",
    "        self.len_cats = len(features_AS)\n",
    "\n",
    "        all_as_combs = list(itertools.product(\n",
    "            self.all_as, repeat=self.len_cats))\n",
    "\n",
    "        self.all_as_df = pd.DataFrame(all_as_combs, columns=self.features_AS)\n",
    "        self.all_as_df_encoded = self.make_t_scale_df(\n",
    "            self.all_as_df[self.features_AS])\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.model_type = model_type\n",
    "\n",
    "        self.testing = testing\n",
    "\n",
    "    def prepare_encoding(self, components):\n",
    "\n",
    "        pc = PCA(n_components=components)\n",
    "        pc = pc.fit_transform(np.stack(self.encoding.values()))\n",
    "\n",
    "        encoding_df = pd.DataFrame({\"AS\": list(self.encoding.keys())})\n",
    "\n",
    "        for i in range(pc.shape[1]):\n",
    "            encoding_df[\"f_\"+str(i)] = pc[:, i]\n",
    "\n",
    "        for t in encoding_df.columns[1:]:\n",
    "            sclr = StandardScaler()\n",
    "            encoding_df[t] = sclr.fit_transform(\n",
    "                np.array(encoding_df[t]).reshape((-1, 1)))\n",
    "\n",
    "        self.encoding_df = encoding_df\n",
    "\n",
    "    def make_t_scale_df(self, df):\n",
    "\n",
    "        cols = df.columns\n",
    "        for t, i in enumerate(cols):\n",
    "            df = pd.merge(df, self.encoding_df, how=\"left\",\n",
    "                          left_on=i, right_on=\"AS\")\n",
    "            df.drop(\"AS\", axis=1, inplace=True)\n",
    "            keep_cols = self.encoding_df.columns[1:]\n",
    "            df.rename(columns={x: str(x) + \"_\" + str(t + 1)\n",
    "                      for x in keep_cols}, inplace=True)\n",
    "        df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def update_dfs(self, components):\n",
    "        self.prepare_encoding(components)\n",
    "\n",
    "        self.encoded_as_df = self.make_t_scale_df(self.df[self.features_AS])\n",
    "        self.all_as_df_encoded = self.make_t_scale_df(\n",
    "            self.all_as_df[self.features_AS])\n",
    "\n",
    "    def predict(self, n_splits=10):\n",
    "\n",
    "        self.target = np.log1p(self.y)\n",
    "\n",
    "        n_splits = 10\n",
    "\n",
    "        cv = KFold(n_splits=n_splits)\n",
    "\n",
    "        self.oof_pred = np.zeros(len(self.encoded_as_df))\n",
    "        self.oof_all_as_pred = np.zeros(len(self.all_as_df_encoded))\n",
    "\n",
    "        for t, (train_idx, val_idx) in enumerate(cv.split(self.encoded_as_df)):\n",
    "            x_train, y_train = self.encoded_as_df.iloc[train_idx], self.target[train_idx]\n",
    "            x_val, y_val = self.encoded_as_df.iloc[val_idx], self.target[val_idx]\n",
    "\n",
    "            #kernel =  RBF(length_scale_bounds = \"fixed\")\n",
    "\n",
    "            if self.model_type == \"gp\":\n",
    "                kernel = Matern(length_scale=1., nu=1.5)\n",
    "                lreg = GaussianProcessRegressor(kernel)\n",
    "\n",
    "            elif self.model_type == \"rf\":\n",
    "                lreg = RandomForestRegressor()\n",
    "\n",
    "            lreg.fit(x_train, y_train)\n",
    "            yhat = lreg.predict(x_val)\n",
    "\n",
    "            if not self.testing:\n",
    "                if len(self.all_as_df_encoded) <= 20**3:\n",
    "                    yhat_pred = lreg.predict(self.all_as_df_encoded).astype(\n",
    "                        \"float16\")  # np.ones(len(self.all_as_df_encoded))\n",
    "\n",
    "                else:\n",
    "                    yhat_pred = []\n",
    "                    for sub_df in np.array_split(self.all_as_df_encoded, 25):\n",
    "                        # print(sub_df.shape)\n",
    "                        yhat_pred_sub = lreg.predict(sub_df).astype(\"float16\")\n",
    "                        yhat_pred = np.concatenate([yhat_pred, yhat_pred_sub])\n",
    "\n",
    "            else:\n",
    "                yhat_pred = np.ones(len(self.all_as_df_encoded))\n",
    "\n",
    "            yhat = np.expm1(yhat.clip(0, 10))\n",
    "            yhat_pred = np.expm1(yhat_pred.clip(0, 10))\n",
    "\n",
    "            self.oof_pred[val_idx] = yhat\n",
    "            self.oof_all_as_pred += yhat_pred / n_splits\n",
    "\n",
    "            r2 = r2_score(np.expm1(y_val), yhat)\n",
    "            mse = mean_squared_error(np.expm1(y_val), yhat)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"{r2}\")\n",
    "\n",
    "        print(f\"final r2: {r2_score(np.expm1(self.target),self.oof_pred)}\")\n",
    "        print(\n",
    "            f\"final mse: {mean_squared_error(np.expm1(self.target),self.oof_pred)}\")\n",
    "        self.final_r2 = r2_score(np.expm1(self.target), self.oof_pred)\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        lreg = LinearRegression()\n",
    "\n",
    "        lreg.fit(self.oof_pred.reshape(-1, 1), self.y.values.reshape(-1, 1))\n",
    "\n",
    "        x = np.linspace(0, self.oof_pred.max() +\n",
    "                        self.oof_pred.max()*0.1, 300).reshape(-1, 1)\n",
    "        y = lreg.predict(x)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.scatter(self.oof_pred, self.y)\n",
    "        plt.xlabel(\"predicted values\", fontsize=15)\n",
    "        plt.ylabel(\"measured values\", fontsize=15)\n",
    "        plt.plot(x, y, c=\"r\")\n",
    "\n",
    "    @staticmethod\n",
    "    def seed_everything(seed=0):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"library16_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_mutations = {}\n",
    "for u in data.library.unique():\n",
    "    libs = []\n",
    "    for c in [97, 174, 238, 241, 242, 245]:\n",
    "        am = len(data.loc[data.library == u, c].value_counts())\n",
    "\n",
    "        if am > 4:\n",
    "            libs.append(c)\n",
    "\n",
    "    libraries_mutations[u] = libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13: [174, 238, 241, 242, 245],\n",
       " 12: [174, 238, 241],\n",
       " 11: [238, 241, 242],\n",
       " 10: [241, 242, 245],\n",
       " 9: [174, 242, 245],\n",
       " 'single': [97, 174, 238, 241, 242, 245]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libraries_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2453\n",
      "0.517710517749248\n",
      "0.5444651276400366\n",
      "0.5731127269649066\n",
      "0.7826878388432748\n",
      "0.804462778627905\n",
      "0.8126885925182359\n",
      "0.6837524577824216\n",
      "0.7117470587591613\n",
      "0.5307751337829878\n",
      "0.8391879096053694\n",
      "final r2: 0.7696547119752704\n",
      "final mse: 0.07484251153982062\n",
      "******************** 0.5414771472857689\n"
     ]
    }
   ],
   "source": [
    "feature_cols = libraries_mutations[13]\n",
    "target_cols = \"FO_WT\"\n",
    "\n",
    "test_lin = data.loc[data.library.isin([9, 10, 12, 13])].reset_index(drop=True)\n",
    "test_lin[\"FO_WT\"] = test_lin.groupby(\"variant\")[\"FO_WT\"].transform(\"mean\")\n",
    "\n",
    "test_lin = test_lin.drop_duplicates(subset=\"variant\").reset_index(drop=True)\n",
    "len_before = len(test_lin)\n",
    "\n",
    "as_test = [\"R\", \"H\", \"K\", \"D\", \"E\", \"S\", \"T\", \"N\", \"Q\",\n",
    "           \"C\", \"G\", \"P\", \"A\", \"V\", \"I\", \"L\", \"M\", \"F\", \"W\", \"Y\"]\n",
    "test_lin = test_lin[test_lin[feature_cols].apply(\n",
    "    lambda x: all(x.isin(as_test)), axis=1)].reset_index(drop=True)\n",
    "len_after = len(test_lin)\n",
    "\n",
    "print(len_after)\n",
    "\n",
    "test_lin[target_cols] = test_lin[target_cols].apply(lambda x: max(0, x))\n",
    "\n",
    "t = do_ml(test_lin, feature_cols, target_cols, aa_index,\n",
    "          verbose=True, components=13, model_type=\"gp\", testing=False)\n",
    "t.predict()\n",
    "\n",
    "df5_only = list(t.df[t.df[\"library\"] == 13].index)\n",
    "df5_r2 = r2_score(np.expm1(t.target[df5_only]), t.oof_pred[df5_only])\n",
    "\n",
    "print(\"*\" * 20, df5_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df = t.all_as_df\n",
    "all5df[\"preds\"] = t.oof_all_as_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df = all5df.sort_values(\"preds\", ascending=False)[\n",
    "    :10000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df[\"variant\"] = all5df[all5df.columns[:-1]\n",
    "                           ].apply(lambda x: \"\".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df[\"variant\"] = all5df.variant.apply(lambda x: \"W\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df = all5df.loc[~all5df.variant.isin(\n",
    "    test_lin.variant)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all5df.to_excel(\"lib_16_predictions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
